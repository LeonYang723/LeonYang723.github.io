<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8">
  <title>ESP32 臉部辨識門鎖</title>
  <script src="./face-api.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      background: #f0f0f0;
      padding: 20px;
      text-align: center;
    }

    .btn-container {
      margin-bottom: 20px;
    }

    button {
      padding: 10px 20px;
      font-size: 16px;
      border: none;
      border-radius: 8px;
      background: #007bff;
      color: white;
      cursor: pointer;
      margin: 5px;
    }

    #videoContainer {
      position: relative;
      width: 100%;
      max-width: 360px;
      margin: 0 auto;
      background: black;
    }

    video {
      width: 100%;
      border-radius: 10px;
    }

    canvas#overlay {
      position: absolute;
      top: 0;
      left: 0;
    }

    #chartContainer {
      margin-top: 20px;
      max-width: 360px;
      margin-left: auto;
      margin-right: auto;
    }

    #status {
      margin-top: 10px;
      font-size: 14px;
      color: gray;
    }
  </style>
</head>
<body>
  <h2>🔐 臉部辨識門鎖</h2>

  <div class="btn-container">
    <button id="connectBtn">🔗 連接 ESP32</button>
    <button id="identifyBtn" disabled>🧠 開始辨識</button>
  </div>

  <!-- 鏡頭區域 -->
  <div id="videoContainer">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>
  </div>

  <!-- 放在鏡頭下方 -->
  <div id="chartContainer">
    <canvas id="scoreChart"></canvas>
  </div>

  <div id="status">📦 載入中...</div>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("overlay");
    const ctx = canvas.getContext("2d");
    const statusEl = document.getElementById("status");

    const connectBtn = document.getElementById("connectBtn");
    const identifyBtn = document.getElementById("identifyBtn");

    let UARTService;
    let knownDescriptors = [];

    const UART_SERVICE = "6e400001-b5a3-f393-e0a9-e50e24dcca9e";
    const RX_UUID = "6e400002-b5a3-f393-e0a9-e50e24dcca9e";

    // Chart.js 設定
    const chart = new Chart(document.getElementById("scoreChart").getContext("2d"), {
      type: "bar",
      data: {
        labels: [],
        datasets: [{
          label: "Similarity Score",
          data: [],
          backgroundColor: "rgba(0, 123, 255, 0.5)"
        }]
      },
      options: {
        responsive: true,
        scales: {
          y: { beginAtZero: true, max: 1 }
        }
      }
    });

    async function loadModels() {
      statusEl.textContent = "📦 載入模型中...";
      await faceapi.nets.tinyFaceDetector.loadFromUri("./models");
      await faceapi.nets.faceLandmark68Net.loadFromUri("./models");
      await faceapi.nets.faceRecognitionNet.loadFromUri("./models");
      await loadReferenceFaces();
      statusEl.textContent = "✅ 模型載入完成！";
    }

    async function loadReferenceFaces() {
      const labels = ["1", "2", "3"];
      for (let label of labels) {
        const img = await faceapi.fetchImage(`./faces/${label}.jpg`);
        const detection = await faceapi
          .detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks()
          .withFaceDescriptor();
        if (detection) {
          knownDescriptors.push({ label, descriptor: detection.descriptor });
        }
      }
    }

    async function startVideo() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      video.onloadedmetadata = () => {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        video.play();
        statusEl.textContent = "📷 攝影機已啟動";
      };
    }

    async function connectBLE() {
      const device = await navigator.bluetooth.requestDevice({
        acceptAllDevices: true,
        optionalServices: [UART_SERVICE]
      });
      const server = await device.gatt.connect();
      UARTService = await server.getPrimaryService(UART_SERVICE);
      identifyBtn.disabled = false;
      await startVideo();
    }

    async function identifyFace() {
      const result = await faceapi
        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (!result) {
        statusEl.textContent = "😕 沒有偵測到人臉";
        return;
      }

      const descriptor = result.descriptor;
      const results = knownDescriptors.map(item => ({
        label: item.label,
        dist: faceapi.euclideanDistance(descriptor, item.descriptor)
      }));

      const min = results.sort((a, b) => a.dist - b.dist)[0];

      // 畫圖表
      chart.data.labels = results.map(r => r.label);
      chart.data.datasets[0].data = results.map(r => r.dist);
      chart.update();

      // 傳送藍芽指令
      const txChar = await UARTService.getCharacteristic(RX_UUID);
      if (min && min.dist < 0.6) {
        await txChar.writeValue(new TextEncoder().encode("UNLOCK"));
        statusEl.textContent = `✅ 成功辨識為 ${min.label}.jpg`;
      } else {
        await txChar.writeValue(new TextEncoder().encode("FAIL"));
        statusEl.textContent = "❌ 拒絕開鎖";
      }
    }

    connectBtn.onclick = connectBLE;
    identifyBtn.onclick = identifyFace;
    loadModels();
  </script>
</body>
</html>
