<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8">
  <title>ESP32 è‡‰éƒ¨è¾¨è­˜é–€é–</title>
  <script src="./face-api.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      background: #f0f0f0;
      padding: 20px;
      text-align: center;
    }
    .btn-container {
      margin-bottom: 20px;
    }
    button {
      padding: 10px 20px;
      font-size: 16px;
      border: none;
      border-radius: 8px;
      background: #007bff;
      color: white;
      cursor: pointer;
      margin: 5px;
    }
    #videoContainer {
      position: relative;
      width: 100%;
      max-width: 360px;
      margin: 0 auto;
      background: black;
    }
    video, canvas {
      width: 100%;
      border-radius: 10px;
    }
    canvas#overlay {
      position: absolute;
      top: 0;
      left: 0;
    }
    #chartContainer {
      margin-top: 40px;
      max-width: 360px;
      margin-left: auto;
      margin-right: auto;
    }
    #status {
      margin-top: 10px;
      font-size: 14px;
      color: gray;
    }
  </style>
</head>
<body>
  <h2>ğŸ” è‡‰éƒ¨è¾¨è­˜é–€é–</h2>

  <div class="btn-container">
    <button id="connectBtn">ğŸ”— é€£æ¥ ESP32</button>
    <button id="identifyBtn" disabled>ğŸ“¤ å‚³é€å‘é‡</button>
  </div>

  <div id="videoContainer">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>
  </div>

  <div id="chartContainer">
    <canvas id="scoreChart"></canvas>
  </div>

  <div id="status">ğŸ“¦ è¼‰å…¥ä¸­...</div>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("overlay");
    const ctx = canvas.getContext("2d");
    const statusEl = document.getElementById("status");
    const connectBtn = document.getElementById("connectBtn");
    const identifyBtn = document.getElementById("identifyBtn");

    let UARTService;
    const UART_SERVICE = "6e400001-b5a3-f393-e0a9-e50e24dcca9e";
    const RX_UUID = "6e400002-b5a3-f393-e0a9-e50e24dcca9e";

    const chart = new Chart(document.getElementById("scoreChart").getContext("2d"), {
      type: "line",
      data: {
        labels: [],
        datasets: [{
          label: "Vector Value (ç¬¬1ç¶­)",
          data: [],
          borderColor: "blue",
          backgroundColor: "blue",
          pointRadius: 4,
          fill: false,
          tension: 0.2
        }]
      },
      options: {
        responsive: true,
        scales: {
          x: {
            title: { display: true, text: 'Sample Index' }
          },
          y: {
            beginAtZero: true,
            max: 1
          }
        }
      }
    });

    async function loadModels() {
      statusEl.textContent = "ğŸ“¦ è¼‰å…¥æ¨¡å‹ä¸­...";
      await faceapi.nets.tinyFaceDetector.loadFromUri("./models");
      await faceapi.nets.faceLandmark68Net.loadFromUri("./models");
      await faceapi.nets.faceRecognitionNet.loadFromUri("./models");
      statusEl.textContent = "âœ… æ¨¡å‹è¼‰å…¥å®Œæˆï¼Œè«‹é€£æ¥ ESP32";
    }

    async function startVideo() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "user" },
          audio: false
        });
        video.srcObject = stream;
        video.onloadedmetadata = () => {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          video.play();
          statusEl.textContent = "ğŸ“· æ”å½±æ©Ÿå·²å•Ÿå‹•ï¼Œè«‹é–‹å§‹è¾¨è­˜";
        };
      } catch (err) {
        console.error("âŒ ç„¡æ³•å•Ÿç”¨æ”å½±æ©Ÿï¼š", err);
        alert("è«‹å…è¨±ä½¿ç”¨æ”å½±æ©Ÿæ¬Šé™ï¼Œä¸¦ä½¿ç”¨ HTTPS æˆ– localhost é–‹å•Ÿé é¢ã€‚");
      }
    }

    async function connectBLE() {
      try {
        const device = await navigator.bluetooth.requestDevice({
          acceptAllDevices: true,
          optionalServices: [UART_SERVICE]
        });
        const server = await device.gatt.connect();
        UARTService = await server.getPrimaryService(UART_SERVICE);
        identifyBtn.disabled = false;
        await startVideo();
      } catch (err) {
        console.error("âŒ è—ç‰™é€£æ¥å¤±æ•—ï¼š", err);
        statusEl.textContent = "âŒ è—ç‰™é€£æ¥å¤±æ•—";
      }
    }

    async function identifyFace() {
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      const result = await faceapi
        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions({ inputSize: 160, scoreThreshold: 0.5 }))
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (!result) {
        statusEl.textContent = "âŒ ç„¡æ³•åµæ¸¬äººè‡‰";
        return;
      }

      const descriptor = result.descriptor;
      const faceVector = Array.from(descriptor).map(n => n.toFixed(6)).join(",");

      // ç™¼é€åˆ° ESP32
      try {
        const txChar = await UARTService.getCharacteristic(RX_UUID);
        await txChar.writeValue(new TextEncoder().encode(faceVector));
        statusEl.textContent = "âœ… å·²å‚³é€ 128 ç¶­å‘é‡";
      } catch (err) {
        statusEl.textContent = "âŒ å‚³é€å¤±æ•—";
        console.error("BLE å‚³é€éŒ¯èª¤ï¼š", err);
      }

      // åœ–è¡¨ç´€éŒ„ï¼ˆä½¿ç”¨ descriptor[0] ä½œç‚ºä»£è¡¨ï¼‰
      chart.data.labels.push(chart.data.labels.length + 1);
      chart.data.datasets[0].data.push(parseFloat(descriptor[0].toFixed(4)));
      chart.update();
    }

    connectBtn.onclick = connectBLE;
    identifyBtn.onclick = identifyFace;
    loadModels();
  </script>
</body>
</html>
