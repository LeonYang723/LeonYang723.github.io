<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>ESP32 äººè‡‰è¾¨è­˜é–€é–</title>
  <script src="./face-api.min.js"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      margin: 0;
      padding: 20px;
      background-color: #f4f4f4;
    }
    h2 {
      margin-bottom: 20px;
    }
    video, canvas {
      border-radius: 10px;
      margin-top: 10px;
      max-width: 100%;
      height: auto;
    }
    #videoContainer {
      position: relative;
      display: inline-block;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
    button {
      padding: 10px 20px;
      font-size: 16px;
      margin: 5px;
      cursor: pointer;
      border: none;
      border-radius: 6px;
      background-color: #007bff;
      color: white;
    }
  </style>
</head>
<body>
  <h2>ğŸ” è‡‰éƒ¨è¾¨è­˜é–€é–</h2>
  <button id="connectBtn">ğŸ”— é€£æ¥ ESP32</button>
  <button id="identifyBtn" disabled>ğŸ§  è¾¨è­˜</button>

  <div id="videoContainer">
    <video id="video" autoplay muted playsinline width="320" height="240"></video>
    <canvas id="overlay"></canvas>
  </div>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("overlay");
    const ctx = canvas.getContext("2d");
    const identifyBtn = document.getElementById("identifyBtn");

    let UARTService;
    const UART_SERVICE = "6e400001-b5a3-f393-e0a9-e50e24dcca9e";
    const RX_UUID = "6e400002-b5a3-f393-e0a9-e50e24dcca9e";

    async function loadModels() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('./models');
      await faceapi.nets.faceRecognitionNet.loadFromUri('./models');
      await faceapi.nets.faceLandmark68Net.loadFromUri('./models');
      console.log("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆï¼");
    }

    async function startVideo() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;

      video.onloadedmetadata = () => {
        video.play();
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        console.log("ğŸ¥ æ”å½±æ©Ÿå•Ÿå‹•");
      };
    }

    async function connectBLE() {
      try {
        const device = await navigator.bluetooth.requestDevice({
          acceptAllDevices: true,
          optionalServices: [UART_SERVICE],
        });
        const server = await device.gatt.connect();
        UARTService = await server.getPrimaryService(UART_SERVICE);
        identifyBtn.disabled = false;
        console.log("âœ… ESP32 å·²é€£ç·š");
      } catch (e) {
        alert("âŒ è—ç‰™é€£ç·šå¤±æ•—ï¼š" + e);
      }
    }

    async function identifyFace() {
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      const result = await faceapi
        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (!result) {
        alert("ğŸ˜• æ²’æœ‰åµæ¸¬åˆ°äººè‡‰ï¼Œè«‹é è¿‘ä¸€é»å†è©¦è©¦ï¼");
        return;
      }

      // ç•«å‡ºäººè‡‰æ¡†
      const resized = faceapi.resizeResults(result, {
        width: video.videoWidth,
        height: video.videoHeight,
      });
      faceapi.draw.drawDetections(canvas, resized);
      faceapi.draw.drawFaceLandmarks(canvas, resized);

      const descriptor = result.descriptor.map(x => x.toFixed(5)).join(",");
      const txChar = await UARTService.getCharacteristic(RX_UUID);
      await txChar.writeValue(new TextEncoder().encode(descriptor));
      console.log("ğŸ“¡ å·²å‚³é€ 128 ç¶­ç‰¹å¾µå‘é‡");
    }

    document.getElementById("connectBtn").onclick = connectBLE;
    document.getElementById("identifyBtn").onclick = identifyFace;

    loadModels();
    startVideo();
  </script>
</body>
</html>
