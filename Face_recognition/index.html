<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>ESP32 äººè‡‰è¾¨è­˜é–€é–</title>
  <script src="./face-api.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 20px;
      background-color: #f0f0f0;
      display: flex;
      flex-direction: column;
      align-items: center;
    }

    h2 {
      margin-bottom: 20px;
    }

    .btn-container {
      display: flex;
      gap: 10px;
      margin-bottom: 20px;
      flex-wrap: wrap;
      justify-content: center;
    }

    button {
      padding: 12px 20px;
      font-size: 16px;
      border: none;
      border-radius: 8px;
      background-color: #007bff;
      color: white;
      cursor: pointer;
    }

    #videoContainer {
      position: relative;
      width: 100%;
      max-width: 640px;
      aspect-ratio: 4/3;
      overflow: hidden;
      margin-bottom: 20px;
    }

    video, canvas {
      width: 100%;
      height: 100%;
      border-radius: 12px;
      position: absolute;
      top: 0;
      left: 0;
    }

    #chartWrapper {
      width: 100%;
      max-width: 640px;
      margin-bottom: 20px;
    }

    #status {
      color: gray;
      font-size: 14px;
      text-align: center;
    }
  </style>
</head>
<body>
  <h2>ğŸ” è‡‰éƒ¨è¾¨è­˜é–€é–</h2>

  <div class="btn-container">
    <button id="connectBtn">ğŸ”— é€£æ¥ ESP32</button>
    <button id="identifyBtn" disabled>ğŸ§  é–‹å§‹è¾¨è­˜</button>
  </div>

  <div id="videoContainer">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>
  </div>

  <!-- âœ… åœ–è¡¨å€å¡Šï¼šå·²ç§»å‹•åˆ°é¡é ­ä¸‹æ–¹ -->
  <div id="chartWrapper">
    <canvas id="scoreChart"></canvas>
  </div>

  <div id="status">ğŸ“¦ æ­£åœ¨è¼‰å…¥æ¨¡å‹...</div>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("overlay");
    const ctx = canvas.getContext("2d");
    const statusEl = document.getElementById("status");
    const connectBtn = document.getElementById("connectBtn");
    const identifyBtn = document.getElementById("identifyBtn");

    let UARTService;
    let knownDescriptors = [];
    const UART_SERVICE = "6e400001-b5a3-f393-e0a9-e50e24dcca9e";
    const RX_UUID = "6e400002-b5a3-f393-e0a9-e50e24dcca9e";

    const chartCtx = document.getElementById("scoreChart").getContext("2d");
    const chartData = {
      labels: [],
      datasets: [{
        label: "Similarity Score",
        backgroundColor: "rgba(0, 123, 255, 0.5)",
        borderColor: "blue",
        data: [],
      }]
    };
    const chart = new Chart(chartCtx, {
      type: "line",
      data: chartData,
      options: {
        responsive: true,
        scales: {
          y: { min: 0, max: 1 }
        }
      }
    });

    async function loadModels() {
      try {
        statusEl.textContent = "ğŸ“¦ æ­£åœ¨è¼‰å…¥æ¨¡å‹...";
        await faceapi.nets.tinyFaceDetector.loadFromUri('./models');
        await faceapi.nets.faceLandmark68Net.loadFromUri('./models');
        await faceapi.nets.faceRecognitionNet.loadFromUri('./models');
        await loadReferenceFaces();
        statusEl.textContent = "âœ… æ¨¡å‹èˆ‡äººè‡‰è³‡æ–™è¼‰å…¥å®Œæˆï¼Œè«‹é€£æ¥ ESP32ã€‚";
      } catch (err) {
        console.error("âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼š", err);
        statusEl.textContent = "âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥ ./models èˆ‡ ./faces è³‡æ–™å¤¾";
      }
    }

    async function loadReferenceFaces() {
      const labels = ["1", "2", "3"];
      for (let label of labels) {
        const img = await faceapi.fetchImage(`./faces/${label}.jpg`);
        const detection = await faceapi
          .detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks()
          .withFaceDescriptor();
        if (detection) {
          knownDescriptors.push({ label, descriptor: detection.descriptor });
          console.log(`âœ… è¼‰å…¥ ${label}.jpg æˆåŠŸ`);
        } else {
          console.warn(`âš ï¸ ${label}.jpg ç„¡äººè‡‰`);
        }
      }
    }

    async function startVideo() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" } });
        video.srcObject = stream;
        video.onloadedmetadata = () => {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          video.play();
          statusEl.textContent = "ğŸ“· æ”å½±æ©Ÿå·²å•Ÿå‹•ï¼Œè«‹é–‹å§‹è¾¨è­˜";
        };
      } catch (err) {
        alert("âŒ æ”å½±æ©Ÿå•Ÿå‹•å¤±æ•—");
        console.error(err);
      }
    }

    async function connectBLE() {
      try {
        const device = await navigator.bluetooth.requestDevice({
          acceptAllDevices: true,
          optionalServices: [UART_SERVICE]
        });
        const server = await device.gatt.connect();
        UARTService = await server.getPrimaryService(UART_SERVICE);
        identifyBtn.disabled = false;
        await startVideo();
        statusEl.textContent = "âœ… å·²é€£ç·š ESP32ï¼Œè«‹é€²è¡Œè¾¨è­˜";
      } catch (err) {
        alert("âŒ è—ç‰™é€£æ¥å¤±æ•—ï¼š" + err);
      }
    }

    async function identifyFace() {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      try {
        const result = await faceapi
          .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks()
          .withFaceDescriptor();
        if (!result) {
          statusEl.textContent = "ğŸ˜• æ²’æœ‰åµæ¸¬åˆ°äººè‡‰ï¼Œè«‹é è¿‘ä¸€é»...";
          return;
        }

        const resized = faceapi.resizeResults(result, {
          width: canvas.width,
          height: canvas.height
        });

        const descriptor = result.descriptor;
        const bestMatch = knownDescriptors
          .map(item => ({
            label: item.label,
            dist: faceapi.euclideanDistance(descriptor, item.descriptor)
          }))
          .sort((a, b) => a.dist - b.dist)[0];

        const score = bestMatch.dist;
        chart.data.labels.push(new Date().toLocaleTimeString());
        chart.data.datasets[0].data.push(score);
        chart.update();

        const txChar = await UARTService.getCharacteristic(RX_UUID);
        const boxColor = score < 0.6 ? "green" : "red";

        const drawBox = new faceapi.draw.DrawBox(resized.detection.box, {
          label: `${bestMatch.label}.jpg (${score.toFixed(2)})`,
          boxColor: boxColor
        });
        drawBox.draw(canvas);

        if (score < 0.6) {
          await txChar.writeValue(new TextEncoder().encode("UNLOCK"));
          statusEl.textContent = `âœ… æˆåŠŸè¾¨è­˜ç‚º ${bestMatch.label}.jpgï¼Œé–€å·²è§£é–`;
        } else {
          await txChar.writeValue(new TextEncoder().encode("FAIL"));
          statusEl.textContent = "âŒ è‡‰éƒ¨ä¸ç¬¦ï¼Œæ‹’çµ•è§£é–";
        }
      } catch (err) {
        console.error("âŒ è¾¨è­˜éŒ¯èª¤ï¼š", err);
        statusEl.textContent = "âŒ è¾¨è­˜å¤±æ•—ï¼Œè«‹é‡è©¦";
      }
    }

    connectBtn.onclick = connectBLE;
    identifyBtn.onclick = identifyFace;
    loadModels();
  </script>
</body>
</html>
