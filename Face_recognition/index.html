<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>ESP32 Face Landmark</title>
  <script src="./face-api.min.js"></script>
  <style>
    video, canvas {
      position: absolute;
      top: 60px;
      left: 0;
    }
    body {
      padding: 20px;
      font-family: Arial;
    }
    button {
      margin-right: 10px;
      padding: 10px;
    }
  </style>
</head>
<body>
  <h3>ESP32 äººè‡‰ 68 ç‰¹å¾µé» BLE</h3>
  <button id="connectBtn">ğŸ”— é€£æ¥ BLE</button>
  <button id="detectBtn" disabled>ğŸ“· é–‹å§‹åµæ¸¬</button>

  <video id="video" autoplay muted playsinline width="640" height="480"></video>
  <canvas id="overlay" width="640" height="480"></canvas>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const ctx = canvas.getContext('2d');
    const connectBtn = document.getElementById('connectBtn');
    const detectBtn = document.getElementById('detectBtn');

    const UART_SERVICE = "6e400001-b5a3-f393-e0a9-e50e24dcca9e";
    const RX_UUID = "6e400002-b5a3-f393-e0a9-e50e24dcca9e";
    let UARTService = null;

    async function connectBLE() {
      try {
        const device = await navigator.bluetooth.requestDevice({
          acceptAllDevices: true,
          optionalServices: [UART_SERVICE],
        });
        const server = await device.gatt.connect();
        UARTService = await server.getPrimaryService(UART_SERVICE);
        console.log("âœ… BLE é€£æ¥æˆåŠŸ");
        detectBtn.disabled = false;
        startVideo();
      } catch (e) {
        console.error("âŒ BLE é€£æ¥éŒ¯èª¤:", e);
      }
    }

    async function startVideo() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
    }

    async function loadModels() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('./models');
      await faceapi.nets.faceLandmark68Net.loadFromUri('./models');
      console.log("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ");
    }

    async function detectLandmarks() {
      console.log("ğŸ” detectLandmarks å•Ÿç”¨");
      const detection = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();
      if (!detection) {
        console.log("âš ï¸ æœªåµæ¸¬åˆ°äººè‡‰");
        return;
      }
      const landmarks = detection.landmarks.positions;
      console.log("ğŸ¯ åµæ¸¬åˆ°ç‰¹å¾µé»æ•¸:", landmarks.length);

      drawLandmarks(landmarks);
      sendToESP32(landmarks);
    }

    function drawLandmarks(landmarks) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.fillStyle = "red";
      landmarks.forEach(pt => {
        ctx.beginPath();
        ctx.arc(pt.x, pt.y, 2, 0, 2 * Math.PI);
        ctx.fill();
      });
    }

    async function sendToESP32(landmarks) {
      if (!UARTService) return;
      const txChar = await UARTService.getCharacteristic(RX_UUID);
      const chunkSize = 17;
      const totalChunks = Math.ceil(landmarks.length / chunkSize);

      for (let i = 0; i < landmarks.length; i += chunkSize) {
        const chunkIndex = Math.floor(i / chunkSize) + 1;
        const chunk = landmarks
          .slice(i, i + chunkSize)
          .map(pt => `${pt.x.toFixed(2)},${pt.y.toFixed(2)}`)
          .join('|');
        const msg = `CHUNK:${chunkIndex}/${totalChunks}|${chunk}`;
        console.log(`ğŸ“¤ å‚³é€:`, msg);
        await txChar.writeValue(new TextEncoder().encode(msg));
        await new Promise(res => setTimeout(res, 200));
      }
    }

    connectBtn.addEventListener('click', connectBLE);
    detectBtn.addEventListener('click', detectLandmarks);
    loadModels();
  </script>
</body>
</html>
