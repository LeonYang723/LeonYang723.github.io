<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ESP32 人臉特徵點偵測</title>
  <script src="./face-api.min.js"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 20px;
      background: #f0f0f0;
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    h2 {
      margin-bottom: 20px;
    }
    .btn-container {
      margin-bottom: 20px;
      display: flex;
      flex-direction: row;
      gap: 10px;
      flex-wrap: wrap;
      justify-content: center;
      width: 100%;
    }
    button {
      padding: 12px 24px;
      font-size: 18px;
      border: none;
      border-radius: 8px;
      background-color: #007bff;
      color: white;
      cursor: pointer;
    }
    #videoContainer {
      position: relative;
      width: 100%;
      max-width: 640px;
      margin: 0 auto;
      background: black;
    }
    video, canvas {
      width: 100%;
      height: auto;
      border-radius: 12px;
      display: block;
      position: absolute;
      top: 0;
      left: 0;
      object-fit: cover;
    }
  </style>
</head>
<body>
  <h2>ESP32 人臉特徵點偵測</h2>
  <div class="btn-container">
    <button id="connectBtn">🔗 連接 BLE</button>
    <button id="detectBtn" disabled>🔍 開始偵測</button>
    <button onclick="captureAndUploadCanvas()">📸 擷取並上傳畫面</button>
  </div>

  <div id="videoContainer">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>
  </div>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("overlay");
    const ctx = canvas.getContext("2d");
    const connectBtn = document.getElementById("connectBtn");
    const detectBtn = document.getElementById("detectBtn");

    let UARTService;
    const UART_SERVICE = "6e400001-b5a3-f393-e0a9-e50e24dcca9e";
    const RX_UUID = "6e400002-b5a3-f393-e0a9-e50e24dcca9e";

    async function connectBLE() {
      try {
        const device = await navigator.bluetooth.requestDevice({
          acceptAllDevices: true,
          optionalServices: [UART_SERVICE],
        });
        const server = await device.gatt.connect();
        UARTService = await server.getPrimaryService(UART_SERVICE);
        console.log("✅ BLE 已連線！");

        detectBtn.disabled = false;
        await startVideo();
      } catch (err) {
        alert("❌ 藍牙連接失敗：" + err);
      }
    }

    async function startVideo() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" } });
        video.srcObject = stream;

        video.onloadedmetadata = () => {
          const w = video.videoWidth || 640;
          const h = video.videoHeight || 480;

          video.style.display = "block";
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          video.play();

          canvas.style.width = video.offsetWidth + "px";
          canvas.style.height = video.offsetHeight + "px";

          console.log("✅ 攝影機啟動完成，尺寸為", w, "x", h);
        };
      } catch (err) {
        alert("❌ 攝影機無法啟動，請確認權限允許！");
        console.error(err);
      }
    }

    async function loadModels() {
      await faceapi.nets.tinyFaceDetector.loadFromUri("./models");
      await faceapi.nets.faceLandmark68Net.loadFromUri("./models");
      console.log("✅ 模型載入完成！");
    }

    async function detectLandmarks() {
      const result = await faceapi
        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks();

      if (!result) {
        console.log("😕 沒有偵測到人臉");
        return;
      }

      const resized = faceapi.resizeResults(result, {
        width: video.videoWidth,
        height: video.videoHeight,
      });

      const landmarks = resized.landmarks.positions;
      drawLandmarks(landmarks);
      sendToESP32(landmarks);
    }

    function drawLandmarks(landmarks) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.fillStyle = "red";
      landmarks.forEach(pt => {
        ctx.beginPath();
        ctx.arc(pt.x, pt.y, 2, 0, 2 * Math.PI);
        ctx.fill();
      });
    }

    async function sendToESP32(landmarks) {
      if (!UARTService) return;
      const txChar = await UARTService.getCharacteristic(RX_UUID);

      const pointsPerChunk = 1;
      const totalChunks = Math.ceil(landmarks.length / pointsPerChunk);

      for (let i = 0; i < landmarks.length; i += pointsPerChunk) {
        const chunkPoints = landmarks.slice(i, i + pointsPerChunk);
        const chunkStr = chunkPoints
          .map(pt => `${pt.x.toFixed(2)},${pt.y.toFixed(2)}`)
          .join("|");

        const chunkIndex = Math.floor(i / pointsPerChunk) + 1;
        const header = `CHUNK:${chunkIndex}/${totalChunks}`;
        const message = `${header}|${chunkStr}`;

        console.log("📤 傳送中：", message);
        await txChar.writeValue(new TextEncoder().encode(message));
        await new Promise(res => setTimeout(res, 100));
      }

      console.log("📡 所有特徵點傳送完成");
    }

    async function captureAndUploadCanvas() {
      const imageData = canvas.toDataURL('image/png');
      const repo = "LeonYang723.github.io";
      const owner = "LeonYang723";
      const token = "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"; // ⚠️ 建議改用 .env 或 server 安全處理
      const fileName = `face_capture_${Date.now()}.png`;
      const content = imageData.split(",")[1];

      const response = await fetch(`https://api.github.com/repos/${owner}/${repo}/contents/captures/${fileName}`, {
        method: "PUT",
        headers: {
          "Authorization": `token ${token}`,
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          message: "upload face capture",
          content: content
        })
      });

      const result = await response.json();
      if (response.ok) {
        console.log("✅ 已成功上傳圖片到 GitHub！網址：", result.content.download_url);
      } else {
        console.error("❌ 上傳失敗", result);
      }
    }

    connectBtn.addEventListener("click", connectBLE);
    detectBtn.addEventListener("click", detectLandmarks);

    loadModels();
  </script>
</body>
</html>
