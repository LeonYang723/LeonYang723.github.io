<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>ESP32 人臉辨識門鎖</title>
  <script src="./face-api.min.js"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 20px;
      background-color: #f0f0f0;
      display: flex;
      flex-direction: column;
      align-items: center;
    }

    h2 {
      margin-bottom: 20px;
    }

    .btn-container {
      display: flex;
      gap: 10px;
      margin-bottom: 20px;
      flex-wrap: wrap;
      justify-content: center;
    }

    button {
      padding: 12px 20px;
      font-size: 16px;
      border: none;
      border-radius: 8px;
      background-color: #007bff;
      color: white;
      cursor: pointer;
    }

    #videoContainer {
      position: relative;
      width: 100%;
      max-width: 640px;
      aspect-ratio: 4/3;
      overflow: hidden;
    }

    video, canvas {
      width: 100%;
      height: 100%;
      border-radius: 12px;
      position: absolute;
      top: 0;
      left: 0;
    }

    #status {
      margin-top: 10px;
      color: gray;
      font-size: 14px;
    }
  </style>
</head>
<body>
  <h2>🔐 臉部辨識門鎖</h2>

  <div class="btn-container">
    <button id="connectBtn">🔗 連接 ESP32</button>
    <button id="identifyBtn" disabled>🧠 開始辨識</button>
  </div>

  <div id="videoContainer">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>
  </div>

  <div id="status">請先連接 ESP32 並等待鏡頭啟動...</div>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("overlay");
    const ctx = canvas.getContext("2d");
    const connectBtn = document.getElementById("connectBtn");
    const identifyBtn = document.getElementById("identifyBtn");
    const statusEl = document.getElementById("status");

    let UARTService;
    const UART_SERVICE = "6e400001-b5a3-f393-e0a9-e50e24dcca9e";
    const RX_UUID = "6e400002-b5a3-f393-e0a9-e50e24dcca9e";

    async function loadModels() {
      try {
        statusEl.textContent = "📦 正在載入模型...";
        await faceapi.nets.tinyFaceDetector.loadFromUri('./models');
        await faceapi.nets.faceLandmark68Net.loadFromUri('./models');
        await faceapi.nets.faceRecognitionNet.loadFromUri('./models');
        console.log("✅ 模型載入完成！");
        statusEl.textContent = "✅ 模型載入完成，請連接 ESP32。";
      } catch (err) {
        console.error("❌ 模型載入失敗：", err);
        statusEl.textContent = "❌ 模型載入失敗，請檢查 ./models 資料夾";
      }
    }

    async function startVideo() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" } });
        video.srcObject = stream;

        video.onloadedmetadata = () => {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          video.play();
          statusEl.textContent = "📷 攝影機已啟動，請按下辨識";
        };
      } catch (err) {
        alert("❌ 攝影機無法啟動，請檢查權限！");
        statusEl.textContent = "❌ 攝影機啟動失敗";
        console.error(err);
      }
    }

    async function connectBLE() {
      try {
        const device = await navigator.bluetooth.requestDevice({
          acceptAllDevices: true,
          optionalServices: [UART_SERVICE]
        });
        const server = await device.gatt.connect();
        UARTService = await server.getPrimaryService(UART_SERVICE);
        console.log("✅ 已連線 ESP32");

        identifyBtn.disabled = false;
        await startVideo();
      } catch (err) {
        alert("❌ 藍牙連接失敗：" + err);
        statusEl.textContent = "❌ 藍牙連線失敗";
      }
    }

    async function identifyFace() {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      try {
        const options = new faceapi.TinyFaceDetectorOptions({
          inputSize: 320,
          scoreThreshold: 0.5
        });

        const result = await faceapi
          .detectSingleFace(video, options)
          .withFaceLandmarks()
          .withFaceDescriptor();

        if (!result) {
          statusEl.textContent = "😕 沒有偵測到人臉，請靠近一點...";
          return;
        }

        const resized = faceapi.resizeResults(result, {
          width: canvas.width,
          height: canvas.height
        });

        faceapi.draw.drawDetections(canvas, resized);
        faceapi.draw.drawFaceLandmarks(canvas, resized);

        const descriptor = result.descriptor.map(x => x.toFixed(5)).join(",");
        const txChar = await UARTService.getCharacteristic(RX_UUID);
        await txChar.writeValue(new TextEncoder().encode(descriptor));
        statusEl.textContent = "📡 特徵已傳送 ESP32！";

      } catch (err) {
        console.error("❌ 辨識過程錯誤：", err);
        statusEl.textContent = "❌ 辨識失敗，請重試";
      }
    }

    connectBtn.onclick = connectBLE;
    identifyBtn.onclick = identifyFace;

    loadModels();
  </script>
</body>
</html>
