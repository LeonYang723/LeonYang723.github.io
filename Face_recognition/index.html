<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>ESP32 è‡‰éƒ¨å‘é‡å‚³é€</title>
  <script src="./face-api.min.js"></script>
  <style>
    body { text-align: center; font-family: sans-serif; background: #f0f0f0; padding: 20px; }
    button { padding: 10px 20px; margin: 10px; font-size: 18px; }
    video { width: 100%; max-width: 400px; border-radius: 12px; margin-top: 10px; }
  </style>
</head>
<body>
  <h2>ESP32 è‡‰éƒ¨å‘é‡å‚³é€</h2>
  <button id="connectBtn">ğŸ”— é€£æ¥ BLE</button>
  <button id="sendBtn" disabled>ğŸ“¤ å‚³é€è‡‰éƒ¨å‘é‡</button>
  <video id="video" autoplay muted playsinline></video>

  <script>
    const UART_SERVICE = "6e400001-b5a3-f393-e0a9-e50e24dcca9e";
    const RX_UUID = "6e400002-b5a3-f393-e0a9-e50e24dcca9e";

    let UARTService = null;
    const video = document.getElementById("video");

    // å•Ÿç”¨é¡é ­
    async function startVideo() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" } });
      video.srcObject = stream;
    }

    // è¼‰å…¥æ¨¡å‹
    async function loadModels() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('./models');
      await faceapi.nets.faceLandmark68Net.loadFromUri('./models');
      await faceapi.nets.faceRecognitionNet.loadFromUri('./models');
      console.log("âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ");
    }

    // BLE è—ç‰™é€£ç·š
    async function connectBLE() {
      const device = await navigator.bluetooth.requestDevice({
        acceptAllDevices: true,
        optionalServices: [UART_SERVICE]
      });
      const server = await device.gatt.connect();
      UARTService = await server.getPrimaryService(UART_SERVICE);
      console.log("âœ… ESP32 è—ç‰™å·²é€£ç·š");
      document.getElementById("sendBtn").disabled = false;
    }

    // æŠ“è‡‰éƒ¨å‘é‡
    async function getFaceVector() {
      const detection = await faceapi
        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (!detection) {
        console.log("âŒ æ²’æœ‰åµæ¸¬åˆ°äººè‡‰");
        return null;
      }

      return detection.descriptor; // 128 ç¶­å‘é‡
    }

    // å‚³é€å‘é‡
    async function sendVectorToESP32(descriptor) {
      const txChar = await UARTService.getCharacteristic(RX_UUID);
      const chunks = [];

      // å°‡æ¯ 4 å€‹æ•¸å€¼ä¸€çµ„åˆ†æ®µ (æœ€å¤š 32 çµ„)
      for (let i = 0; i < descriptor.length; i += 4) {
        const chunk = descriptor.slice(i, i + 4).map(n => n.toFixed(4)).join(",");
        const header = `VEC:${Math.floor(i / 4) + 1}/${Math.ceil(descriptor.length / 4)}`;
        const message = `${header}|${chunk}`;
        chunks.push(message);
      }

      for (const msg of chunks) {
        console.log("ğŸ“¤ å‚³é€ï¼š", msg);
        await txChar.writeValue(new TextEncoder().encode(msg));
        await new Promise(res => setTimeout(res, 100)); // å°å»¶é²
      }

      console.log("âœ… å…¨éƒ¨å‘é‡å‚³é€å®Œæˆ");
    }

    document.getElementById("connectBtn").addEventListener("click", connectBLE);
    document.getElementById("sendBtn").addEventListener("click", async () => {
      const vector = await getFaceVector();
      if (vector) {
        await sendVectorToESP32(vector);
      }
    });

    loadModels();
    startVideo();
  </script>
</body>
</html>
